{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import hashlib\n",
    "import zipfile\n",
    "import glob\n",
    "import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_imgs': True, 'img_folder': True, 'zip': True, 'hash_ok': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\n    os.makedirs(extract_path)\\n    try:\\n        extract_fn(save_path, extract_path, database_name, data_path)\\n    except Exception as err:\\n        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\\n        raise err\\n\\n    # Remove compressed data\\n    os.remove(save_path)    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test existence of data\n",
    "url = 'https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip'\n",
    "hash_code = '00d2c5bc6d35e252742224ab0c1e8fcb'\n",
    "data_path = '../data'\n",
    "zip_file = 'celeba.zip'\n",
    "zip_path = os.path.join(data_path, zip_file)\n",
    "extract_path = os.path.join(data_path, 'img_align_celeba')\n",
    "\n",
    "exists = { \n",
    "    'zip': os.path.exists(zip_path),\n",
    "    'hash_ok': hashlib.md5(open(zip_path, 'rb').read()).hexdigest() == hash_code,\n",
    "    'img_folder': os.path.exists(extract_path), \n",
    "    'all_imgs': len(glob.glob(extract_path+'/*.jpg')) == 202599\n",
    "}\n",
    "\n",
    "print(exists)\n",
    "\n",
    "'''\n",
    "url = 'https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip'\n",
    "hash_code = '00d2c5bc6d35e252742224ab0c1e8fcb'\n",
    "data_path = '../data'\n",
    "zip_file = 'celeba.zip'\n",
    "extract_path = os.path.join(data_path, 'img_align_celeba')\n",
    "save_path = os.path.join(data_path, zip_file)\n",
    "#extract_fn = _unzip'''\n",
    "\n",
    "'''\n",
    "# Download dataset\n",
    "if not os.path.exists(save_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading {}'.format(zip_file)) as pbar:\n",
    "        urlretrieve(url, save_path, pbar.hook)\n",
    "    \n",
    "# Verify hash code\n",
    "assert hashlib.md5(open(save_path, 'rb').read()).hexdigest() == hash_code, \\\n",
    "    '{} file is corrupted.  Remove the file and try again.'.format(save_path)'''\n",
    "\n",
    "'''    \n",
    "    os.makedirs(extract_path)\n",
    "    try:\n",
    "        extract_fn(save_path, extract_path, database_name, data_path)\n",
    "    except Exception as err:\n",
    "        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n",
    "        raise err\n",
    "\n",
    "    # Remove compressed data\n",
    "    os.remove(save_path)    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
